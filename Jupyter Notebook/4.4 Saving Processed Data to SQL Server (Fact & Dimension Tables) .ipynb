{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b25a9c0-9583-4fa5-a94e-35eae4eb8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ef62f29-bf6e-4dbe-952c-ad08181b6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_location = 'archive'\n",
    "\n",
    "filenames = {\n",
    "    \"customers\" : \"olist_customers_dataset.csv\", #Information about customers and their geographic data.\n",
    "    \"geolocation\" : \"olist_geolocation_dataset.csv\",\n",
    "    \"order_items\" : \"olist_order_items_dataset.csv\", #Details about each item in an order, including price, freight value, and the connection between orders and products.\n",
    "    \"order_payments\" : \"olist_order_payments_dataset.csv\", #Payment information associated with each order.\n",
    "    \"order_reviews\" : \"olist_order_reviews_dataset.csv\", #Customer reviews and ratings for orders.\n",
    "    \"orders\" : \"olist_orders_dataset.csv\", #Contains order information such as order status, purchase date, and delivery date.\n",
    "    \"products\" : \"olist_products_dataset.csv\", #Contains product-related information.\n",
    "    \"sellers\" : \"olist_sellers_dataset.csv\", #Details about sellers and their geographic information.\n",
    "    \"product_category_name_translation\" : \"product_category_name_translation.csv\",\n",
    "}\n",
    "customers_df = pd.read_csv(f'{archive_location}/{filenames[\"customers\"]}')\n",
    "geolocation_df = pd.read_csv(f'{archive_location}/{filenames[\"geolocation\"]}')\n",
    "order_items = pd.read_csv(f'{archive_location}/{filenames[\"order_items\"]}')\n",
    "order_payments_df = pd.read_csv(f'{archive_location}/{filenames[\"order_payments\"]}')\n",
    "order_reviews = pd.read_csv(f'{archive_location}/{filenames[\"order_reviews\"]}')\n",
    "orders_df = pd.read_csv(f'{archive_location}/{filenames[\"orders\"]}')\n",
    "products = pd.read_csv(f'{archive_location}/{filenames[\"products\"]}')\n",
    "sellers = pd.read_csv(f'{archive_location}/{filenames[\"sellers\"]}')\n",
    "product_category_name_translation = pd.read_csv(f'{archive_location}/{filenames[\"product_category_name_translation\"]}')\n",
    "\n",
    "# print(f\"Count of rows before dedublication: {str(len(geolocation_df.index))}\")\n",
    "# since the only option to connect geolocation tables with other tables is geolocation_city\tgeolocation_state\tgeolocation_zip_code_prefix I am using this as a subset \n",
    "geolocation_df.drop_duplicates(subset = [\"geolocation_city\",\"geolocation_zip_code_prefix\", \"geolocation_state\"], inplace=True)\n",
    "geolocation_df.reset_index(inplace=True , drop=True)\n",
    "# print(f\"Count of rows after dedublication: {len(geolocation_df.index)}\")\n",
    "\n",
    "# print(orders_df[orders_df[\"order_approved_at\"].isna()].head())\n",
    "orders_df[\"order_delivered_carrier_date\"] = orders_df[\"order_delivered_carrier_date\"].fillna(pd.NaT)\n",
    "orders_df[\"order_approved_at\"] = orders_df[\"order_approved_at\"].fillna(pd.NaT)\n",
    "orders_df[\"order_delivered_customer_date\"] = orders_df[\"order_delivered_customer_date\"].fillna(pd.NaT)\n",
    "# print(orders_df[orders_df[\"order_approved_at\"].isna()].head())\n",
    "\n",
    "\n",
    "# print(products[products[\"product_category_name\"].isna()].head())\n",
    "products[\"product_category_name\"] = products[\"product_category_name\"].fillna('')\n",
    "products[\"product_name_lenght\"] = products[\"product_category_name\"].fillna('')\n",
    "products[\"product_description_lenght\"] = products[\"product_description_lenght\"].fillna(0)\n",
    "products[\"product_photos_qty\"] = products[\"product_photos_qty\"].fillna(0)\n",
    "products[\"product_weight_g\"] = products[\"product_weight_g\"].fillna('')\n",
    "products[\"product_length_cm\"] = products[\"product_length_cm\"].fillna('')\n",
    "products[\"product_photos_qty\"] = products[\"product_photos_qty\"].fillna('')\n",
    "products[\"product_width_cm\"] = products[\"product_width_cm\"].fillna('')\n",
    "# print('\\n\\n----------------')\n",
    "# print(products[products[\"product_category_name\"] == ''].head())\n",
    "\n",
    "\n",
    "# print(order_reviews[order_reviews[\"review_comment_message\"].isna()].head())\n",
    "order_reviews[\"review_comment_title\"] = order_reviews[\"review_comment_title\"].fillna('')\n",
    "order_reviews[\"review_comment_message\"] = order_reviews[\"review_comment_message\"].fillna('')\n",
    "# print(order_reviews[order_reviews[\"review_comment_message\"] == ''].head())\n",
    "\n",
    "\n",
    "# print(\"Calculating total_price\")\n",
    "order_items[\"total_price\"] = order_items[\"freight_value\"] +  order_items[\"price\"]\n",
    "# print(order_items[[\"freight_value\",\"price\",\"total_price\"]].head())\n",
    "\n",
    "\n",
    "# print(\"\\n\\nCalculating delivery_time\")\n",
    "orders_df[\"delivery_time\"] = pd.to_datetime(orders_df[\"order_delivered_customer_date\"]) - pd.to_datetime(orders_df[\"order_purchase_timestamp\"])\n",
    "# print(orders_df[[\"order_delivered_customer_date\",\"order_purchase_timestamp\",\"delivery_time\"]].head())\n",
    "\n",
    "# print(\"\\n\\nAdding delivery_time to order_items\")\n",
    "order_items = pd.merge(order_items, orders_df[['order_id', 'delivery_time']], on='order_id', how='left')\n",
    "# print(order_items['delivery_time'].head())\n",
    "\n",
    "#tbc on negative values\n",
    "# print(\"\\n\\nCalculating profit_margin\")\n",
    "order_items[\"profit_margin\"] = order_items[\"price\"] - order_items[\"freight_value\"]\n",
    "# print(order_items[[\"price\",\"freight_value\",\"profit_margin\"]].sort_values(by=[\"profit_margin\"],ascending=True).head())\n",
    "\n",
    "# print(\"\\n\\nCalculating profit_margin\")\n",
    "payments_count = order_payments_df.groupby('order_id').size().reset_index(name='payments_count')\n",
    "orders_df = orders_df.merge(payments_count, on='order_id', how='left')\n",
    "orders_df['payments_count'] = orders_df['payments_count'].fillna(0)\n",
    "orders_df['payments_count'] = orders_df['payments_count'].astype(int)\n",
    "\n",
    "# print(orders_df['payments_count'].head())\n",
    "\n",
    "orders_with_price_df = pd.merge(orders_df, order_items[['order_id', 'total_price']], on='order_id', how='left')\n",
    "\n",
    "orders_with_price_df['running_total'] = orders_with_price_df.groupby('customer_id')['total_price'].cumsum()\n",
    "\n",
    "#to show the running total of product price for each customer\n",
    "# testorders_with_price_df = orders_with_price_df[orders_with_price_df[\"customer_id\"] == '1617b1357756262bfa56ab541c47bc16']\n",
    "# print(testorders_with_price_df[[\"customer_id\",\"total_price\",\"running_total\"]].head())\n",
    "\n",
    "\n",
    "orders_df['delivery_time'] = pd.to_numeric(orders_df['delivery_time'], errors='coerce')\n",
    "\n",
    "orders_with_productId_df = pd.merge(orders_df, order_items[['order_id', 'product_id']], on='order_id', how='left')\n",
    "# print(orders_with_productId_df.head())\n",
    "orders_with_product_category_df = pd.merge(orders_with_productId_df, products[['product_id', 'product_category_name']], on='product_id', how='left')\n",
    "# print(orders_with_product_category_df.head())\n",
    "\n",
    "orders_with_product_category_df['rolling_average_delivery_time'] = orders_with_product_category_df.groupby('product_category_name')['delivery_time'].rolling(window=2).mean().reset_index(level=0, drop=True)\n",
    "orders_with_product_category_df['delivery_time'] = pd.to_timedelta(orders_with_product_category_df['delivery_time'])\n",
    "orders_with_product_category_df['rolling_average_delivery_time'] = pd.to_timedelta(orders_with_product_category_df['rolling_average_delivery_time'])\n",
    "\n",
    "orders_df['delivery_time'] = pd.to_timedelta(orders_df['delivery_time'])\n",
    "\n",
    "#to show the rolling of the avg delivery time\n",
    "# testorders_with_product_category_df = orders_with_product_category_df[orders_with_product_category_df[\"product_category_name\"] == \"utilidades_domesticas\"]\n",
    "# print(testorders_with_product_category_df[['product_category_name',\"delivery_time\",\"rolling_average_delivery_time\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37d91f9-3fe6-4c08-ad3d-e73d9b854c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add customer_id to Order Items table to connect with Customers's table\n",
    "\n",
    "db_order_items = pd.merge(order_items, orders_df[['order_id', 'customer_id']], on='order_id', how='left')\n",
    "#rearange columns for better visibility\n",
    "db_order_items = db_order_items[[\"order_id\",\t\"order_item_id\",\t\"product_id\",\t\"seller_id\",\t\"customer_id\",\t\"shipping_limit_date\",\t\"price\",\t\"freight_value\",\t\"total_price\",\t\"profit_margin\",\t\"delivery_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47c68bc3-b7f1-4f61-973f-84f9516fd300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add  geolocation_lat\tgeolocation_lng to Customers's table\n",
    "\n",
    "db_customers_df = pd.merge(\n",
    "    customers_df,\n",
    "    geolocation_df,\n",
    "    left_on=['customer_zip_code_prefix', 'customer_city', 'customer_state'],\n",
    "    right_on=['geolocation_zip_code_prefix', 'geolocation_city', 'geolocation_state'],\n",
    "    how='left'  # Use 'left' to keep all records from customers_df\n",
    ")\n",
    "\n",
    "db_customers_df = db_customers_df[['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state', 'geolocation_lat', 'geolocation_lng']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "911ed3c2-7f11-47e3-810e-ef45eaf6a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_products = products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "291333d5-466c-47bd-af98-2db89e100ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_sellers =  pd.merge(\n",
    "    sellers,\n",
    "    geolocation_df,\n",
    "    left_on=['seller_zip_code_prefix', 'seller_city', 'seller_state'],\n",
    "    right_on=['geolocation_zip_code_prefix', 'geolocation_city', 'geolocation_state'],\n",
    "    how='left'  # Use 'left' to keep all records from customers_df\n",
    ")\n",
    "\n",
    "db_sellers = db_sellers[[\"seller_id\", \"seller_zip_code_prefix\", \"seller_city\", \"seller_state\", \"geolocation_lat\", \"geolocation_lng\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82979b21-7cb4-4660-8a0b-d485e130936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_order_purchase_date = orders_df[[\"order_purchase_timestamp\",\"order_delivered_customer_date\",\"delivery_time\"]]\n",
    "db_order_purchase_date = db_order_purchase_date.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5d02c49-94f8-4703-892d-72fc2bce547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_18744\\2296086294.py:27: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  db_order_items.to_sql('db_order_items', engine, if_exists='replace', index=False)\n",
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_18744\\2296086294.py:31: UserWarning: the 'timedelta' type is not supported, and will be written as integer values (ns frequency) to the database.\n",
      "  db_order_purchase_date.to_sql('db_order_purchase_date', engine, if_exists='replace', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames successfully uploaded to SQL Server!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "params = urllib.parse.quote_plus(\n",
    "    \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "    \"SERVER=localhost;\"\n",
    "    \"DATABASE=LH;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "engine = create_engine(f'mssql+pyodbc:///?odbc_connect={params}')\n",
    "\n",
    "\n",
    "db_order_items.to_sql('db_order_items', engine, if_exists='replace', index=False)\n",
    "db_customers_df.to_sql('db_customers_df', engine, if_exists='replace', index=False)\n",
    "db_products.to_sql('db_products', engine, if_exists='replace', index=False)\n",
    "db_sellers.to_sql('db_sellers', engine, if_exists='replace', index=False)\n",
    "db_order_purchase_date.to_sql('db_order_purchase_date', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"DataFrames successfully uploaded to SQL Server!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe481c42-74e5-4ce5-8ba1-b2beb72a9f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
